{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Owner: Amitabh Bhattacharya\n",
    "# email: a.bhattacharya@unf.edu\n",
    "\n",
    "# Importing necessary packages\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from functools import reduce\n",
    "\n",
    "import sklearn.metrics as met\n",
    "warnings.simplefilter(action = 'ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quinlanâ€™s ID3 and C4.5 decision tree learning algorithm\n",
    "\n",
    "# The class is the node of a decision tree. It can be a root, intermediate node or a leaf node.\n",
    "# Leaf node means it is the label\n",
    "class Node:    \n",
    "    # Constructor\n",
    "    def __init__(self, col=None, dec=None):\n",
    "        # Either col or dec should be None (Internal node or leaf)\n",
    "        self.name = col\n",
    "        self.decision = dec\n",
    "        self.branches = []\n",
    "        self.branch_names = []\n",
    "        \n",
    "    # This function is used to do post-pruning of the trained decision tree\n",
    "    # The method is not implemented in this version\n",
    "    def prune():\n",
    "        pass\n",
    "\n",
    "    # This function is used to predict the test dataset.\n",
    "    def predict(self, df):\n",
    "        prediction = []\n",
    "        \n",
    "        for ind, row in df.iterrows():\n",
    "            result = self.row_predict(row)\n",
    "            prediction.append(result)\n",
    "            \n",
    "        return pd.Series(prediction)        \n",
    "    \n",
    "    def row_predict(self, row):\n",
    "        pred = \"\"\n",
    "        if self.name != None:\n",
    "            att = self.name\n",
    "            att_val = row[att]\n",
    "            att_ind = self.branch_names.index(att_val)\n",
    "            att_br_tree = self.branches[att_ind]\n",
    "\n",
    "            pred = att_br_tree.row_predict(row)            \n",
    "        else:\n",
    "            return self.decision\n",
    "        \n",
    "        return pred\n",
    "                \n",
    "\n",
    "    # The below function is to print the decision tree. \n",
    "    # It prints internal node/leaf with the information about the level it belongs.\n",
    "    def print(self, name=\"Root\", lev=0):       \n",
    "        if self.name != None:\n",
    "            print(lev*\"   \" + \"-(\" + name + \")-> \" + \"N: \", self.name)           \n",
    "        \n",
    "            for i in range(len(self.branches)):\n",
    "                n = self.branch_names[i]\n",
    "                b = self.branches[i]\n",
    "                b.print(n, lev+1)\n",
    "        else:\n",
    "            print(lev*\"   \" + \"-(\" + name + \")-> \" + \"L: \", self.decision)\n",
    "    \n",
    "# This function calculates entropy of a column w.r.t. label (y)\n",
    "def entropy(label):\n",
    "    num_unique = label.nunique() \n",
    "    entropy_label = 0\n",
    "    \n",
    "    for i in range(num_unique):\n",
    "        e_vc = label.value_counts()[i]/len(label)\n",
    "        entropy_label += -1 * e_vc * math.log2(e_vc)\n",
    "\n",
    "    return entropy_label\n",
    "\n",
    "# This function calculates the information gain for branching on the column\n",
    "def info_gain(current_ent, col, df):\n",
    "    information = 0\n",
    "    vc = df[col].value_counts()\n",
    "        \n",
    "    for i in range(len(vc)):\n",
    "        p = vc[i]/len(df)  # probality of a particular class in the attribute\n",
    "        # Entropy of the column with the particular class in the attribute\n",
    "        s = entropy(df[df[col] == vc.index[i]].iloc[:,0])\n",
    "        temp_ent = p * s\n",
    "        information += temp_ent\n",
    "        \n",
    "    return round((current_ent - information), 3)\n",
    "\n",
    "# This function calculates the gain ratio for branching on the column\n",
    "def gain_ratio(current_ent, col, df):\n",
    "    information = 0\n",
    "    vc = df[col].value_counts()\n",
    "        \n",
    "    for i in range(len(vc)):\n",
    "        p = vc[i]/len(df)  # probality of a particular class in the attribute\n",
    "        # Entropy of the column with the particular class in the attribute\n",
    "        s = entropy(df[df[col] == vc.index[i]].iloc[:,0])\n",
    "        temp_ent = p * s\n",
    "        information += temp_ent\n",
    "        \n",
    "    gain = current_ent - information\n",
    "    \n",
    "    # Computing the intrinsic value\n",
    "    iv = 0    \n",
    "    for i in range(len(vc)):\n",
    "        iv += -1 * (vc[i]/len(df)) * math.log2(vc[i]/len(df))\n",
    "    \n",
    "    # Gain ratio - gain/intrinsic value \n",
    "    if iv != 0:\n",
    "        gain_ratio = gain/iv\n",
    "    else:\n",
    "        gain_ratio = 0        \n",
    "    \n",
    "    return round(gain_ratio, 3)\n",
    "\n",
    "\n",
    "# This assumes that the the first column in df input is the y label\n",
    "# algorithm = 'id3' for information gain and algorithm = 'c4.5' for gain ratio\n",
    "def fit_dt(df, algorithm = 'id3'):\n",
    "    algo = algorithm\n",
    "    columns = df.columns[1:]  # 0th column is the y label    \n",
    "    current_ent = entropy(df.iloc[:,0]) # Obtaining the current entropy before spliting it.\n",
    "    \n",
    "    # If no features are left to branch or current_entropy is 0 (or nearly 0) then make a leaf\n",
    "    # Entropy value of 0 means y label is perfectly one sided.\n",
    "    if ((len(columns) == 0) | (current_ent < 0.01)):\n",
    "        dec = df.iloc[:,0].value_counts().idxmax()\n",
    "        return Node(None, dec)\n",
    "    \n",
    "    information_gain = [] # This would finally contain all the info gain from all the columns of the dataframe.\n",
    "    \n",
    "    for col in columns:\n",
    "        if algo == 'id3':\n",
    "            ig = info_gain(current_ent, col, df)\n",
    "        elif algo == 'c4.5':\n",
    "            ig = gain_ratio(current_ent, col, df)\n",
    "            \n",
    "        information_gain.append(ig)\n",
    "    \n",
    "    ind = np.argmax(information_gain)\n",
    "    \n",
    "    # This is the internal node of the tree\n",
    "    tree_node = df.columns[ind+1]\n",
    "    \n",
    "    # The Node class object holds internal tree nodes that would be branching.\n",
    "    # fit_dt() function is called recursively to construct/train the Decision Tree.\n",
    "    \n",
    "    i_node = Node(tree_node, None)\n",
    "    branch_val = df[tree_node].unique()\n",
    "    \n",
    "    for brn in branch_val:        \n",
    "        a = list(df.columns)\n",
    "        b = tree_node        \n",
    "        sub_col_list = [v for v in a if v != b]\n",
    "        \n",
    "        # Recursive calling of fit_dt() \n",
    "        sub_tree = fit_dt(df[df[tree_node] == brn][sub_col_list], algorithm = algo)\n",
    "        # sub_tree = fit_dt(df_temp, algorithm = algo)     \n",
    "        i_node.branches.append(sub_tree)\n",
    "        i_node.branch_names.append(brn)\n",
    "    \n",
    "    return i_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training and testing dataset\n",
    "\n",
    "# train = pd.read_csv('Data\\\\training.data', header = None)\n",
    "train_0 = pd.read_csv('Data\\\\training_aa.data', header = None)\n",
    "train_1 = pd.read_csv('Data\\\\training_ab.data', header = None)\n",
    "train_2 = pd.read_csv('Data\\\\training_ac.data', header = None)\n",
    "train_3 = pd.read_csv('Data\\\\training_ad.data', header = None)\n",
    "train_4 = pd.read_csv('Data\\\\training_ae.data', header = None)\n",
    "train_5 = pd.read_csv('Data\\\\training_af.data', header = None)\n",
    "train_6 = pd.read_csv('Data\\\\training_ag.data', header = None)\n",
    "train_7 = pd.read_csv('Data\\\\training_ah.data', header = None)\n",
    "train_8 = pd.read_csv('Data\\\\training_ai.data', header = None)\n",
    "train_9 = pd.read_csv('Data\\\\training_aj.data', header = None)\n",
    "test = pd.read_csv('Data\\\\testing.data', header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best id3 validation score is:  1.0\n",
      "Best c4.53 validation score is:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "train_list = [train_0, train_1, train_2, train_3, train_4, train_5, train_6, train_7, train_8, train_9]\n",
    "\n",
    "def validation(t_list):    \n",
    "    id3_max_score = 0\n",
    "    c45_max_score = 0\n",
    "    id3_best_tree = None\n",
    "    c45_best_tree = None    \n",
    "    \n",
    "    n = len(t_list)    \n",
    "    for i in range(n):\n",
    "        val = t_list[i]  # The validation dataset\n",
    "        del t_list[i]\n",
    "        \n",
    "        train = reduce(lambda x,y: pd.concat([x,y]), t_list) # Merging the remaining 9 training set\n",
    "        id3_temp_tree = fit_dt(train, algorithm = 'id3') # Training the decision tree with the training data\n",
    "        c45_temp_tree = fit_dt(train, algorithm = 'c4.5') # Training the decision tree with the training data\n",
    "    \n",
    "        id3_prediction = id3_temp_tree.predict(val) # Predicting on the validation dataset using the recent trained decision tree\n",
    "        id3_score = met.f1_score(val[0].values, id3_prediction.values, pos_label = 'e') # F1 score computation\n",
    "        \n",
    "        c45_prediction = c45_temp_tree.predict(val) # Predicting on the validation dataset using the recent trained decision tree\n",
    "        c45_score = met.f1_score(val[0].values, c45_prediction.values, pos_label = 'e') # F1 score computation\n",
    "        \n",
    "        if id3_score >= id3_max_score:\n",
    "            id3_max_score = id3_score\n",
    "            id3_best_tree = id3_temp_tree\n",
    "            \n",
    "        if c45_score >= c45_max_score:\n",
    "            c45_max_score = c45_score\n",
    "            c45_best_tree = c45_temp_tree\n",
    "    \n",
    "        train_list.insert(i, val) # Inserting back the validation set in training list for next round.\n",
    "\n",
    "    print(\"Best id3 validation score is: \", id3_max_score)\n",
    "    print(\"Best c4.53 validation score is: \", c45_max_score)\n",
    "    \n",
    "    return (id3_best_tree, c45_best_tree)\n",
    "\n",
    "id3_tree, c45_tree = validation(train_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The c45 tree: \n",
      "---------------------\n",
      "-(Root)-> N:  5\n",
      "   -(n)-> N:  20\n",
      "      -(n)-> L:  e\n",
      "      -(k)-> L:  e\n",
      "      -(w)-> N:  17\n",
      "         -(w)-> N:  8\n",
      "            -(b)-> L:  e\n",
      "            -(n)-> N:  7\n",
      "               -(w)-> N:  4\n",
      "                  -(f)-> L:  e\n",
      "                  -(t)-> L:  p\n",
      "               -(c)-> L:  p\n",
      "         -(y)-> L:  p\n",
      "      -(o)-> L:  e\n",
      "      -(h)-> L:  e\n",
      "      -(b)-> L:  e\n",
      "      -(r)-> L:  p\n",
      "      -(y)-> L:  e\n",
      "   -(s)-> L:  p\n",
      "   -(f)-> L:  p\n",
      "   -(y)-> L:  p\n",
      "   -(l)-> L:  e\n",
      "   -(p)-> L:  p\n",
      "   -(c)-> L:  p\n",
      "   -(a)-> L:  e\n",
      "   -(m)-> L:  p\n",
      "\n",
      "The id3 tree: \n",
      "---------------------\n",
      "-(Root)-> N:  5\n",
      "   -(n)-> N:  20\n",
      "      -(n)-> L:  e\n",
      "      -(k)-> L:  e\n",
      "      -(w)-> N:  22\n",
      "         -(p)-> L:  e\n",
      "         -(g)-> L:  e\n",
      "         -(w)-> L:  e\n",
      "         -(l)-> N:  3\n",
      "            -(n)-> L:  e\n",
      "            -(y)-> L:  p\n",
      "            -(c)-> L:  e\n",
      "            -(w)-> L:  p\n",
      "         -(d)-> N:  8\n",
      "            -(n)-> L:  p\n",
      "            -(b)-> L:  e\n",
      "      -(o)-> L:  e\n",
      "      -(h)-> L:  e\n",
      "      -(b)-> L:  e\n",
      "      -(r)-> L:  p\n",
      "      -(y)-> L:  e\n",
      "   -(s)-> L:  p\n",
      "   -(f)-> L:  p\n",
      "   -(y)-> L:  p\n",
      "   -(l)-> L:  e\n",
      "   -(p)-> L:  p\n",
      "   -(c)-> L:  p\n",
      "   -(a)-> L:  e\n",
      "   -(m)-> L:  p\n"
     ]
    }
   ],
   "source": [
    "# Tree printing\n",
    "print(\"The c45 tree: \")\n",
    "print(\"---------------------\")\n",
    "c45_tree.print()\n",
    "\n",
    "print(\"\")\n",
    "print(\"The id3 tree: \")\n",
    "print(\"---------------------\")\n",
    "id3_tree.print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on test dataset using id3 algorithm is:  1.0\n",
      "F1 score on test dataset using C4.5 algorithm is:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Prediction on testing dataset\n",
    "id3_prediction = id3_tree.predict(test)\n",
    "id3_score = met.f1_score(test[0].values, id3_prediction.values, pos_label = 'e') # F1 score computation\n",
    "\n",
    "c45_prediction = c45_tree.predict(test)\n",
    "c45_score = met.f1_score(test[0].values, c45_prediction.values, pos_label = 'e') # F1 score computation\n",
    "\n",
    "print(\"F1 score on test dataset using id3 algorithm is: \", id3_score)\n",
    "print(\"F1 score on test dataset using C4.5 algorithm is: \", c45_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
